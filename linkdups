#!/usr/bin/perl
#
# linkdups - Find duplicate files in a directory tree and link() them.
#
# Copyright (C) 2000-2022 Steven Pritchard <steven.pritchard@gmail.com>
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License as
# published by the Free Software Foundation; either version 2 of
# the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

use strict;
use warnings;

use Getopt::Std;
use Digest::MD5;
use FileHandle;
use DirHandle;
use File::Basename;
use DBI;
use List::MoreUtils qw(uniq);

use feature qw(state signatures say);
no warnings qw(experimental::signatures);

our $verbose;
our $debug;
our $dryrun;

sub dbver () {
    return 2;
}

sub begin_transaction () {
    return 'begin transaction';
}

sub create_table_linkdups_v1 () {
    return 'create table linkdups ('
        . 'version unsigned integer primary key not null)';

}

sub create_table_inode_v1 () {
    return 'create table inode ('
        . 'id integer primary key not null,'
        . 'dev unsigned integer not null,'
        . 'inum unsigned integer not null,'
        . 'nlink unsigned integer not null,'
        . 'uid unsigned integer not null,'
        . 'gid unsigned integer not null,'
        . 'size unsigned bigint not null,'
        . 'blocks unsigned bigint not null,'
        . 'mtime unsigned bigint not null,'
        . 'md5 char(32))';

}

sub create_index_dev_inum_v2 () {
    return 'create unique index dev_inum on inode (dev, inum)';
}

sub create_trigger_clear_md5_v2 () {
    return 'create trigger clear_md5 after update of size, blocks, mtime on inode for each row'
        . ' when (old.size != new.size or old.blocks != new.blocks or old.mtime != new.mtime)'
        . ' begin'
        . ' update inode set md5=null where id=new.id;'
        . ' end';
}

sub create_table_file_v1 ($temporary) {
    return "create $temporary table file ("
        . 'id integer primary key not null,'
        . 'dev unsigned integer not null,'
        . 'inum unsigned integer not null,'
        . 'name text not null)',
}

sub commit () {
    return 'commit';
}

sub total ($val = 0) {
    state $total = 0;

    $total += $val if $val;

    return $total;
}

sub numtotal ($val = 0) {
    state $numtotal = 0;

    $numtotal += $val if $val;

    return $numtotal;
}

sub num ($val = 0) {
    state $num = 0;

    $num += $val if $val;

    return $num;
}

sub dbh ($dbfile) {
    state %dbh;

    return $dbh{$dbfile} if exists($dbh{$dbfile});

    $dbh{$dbfile} = DBI->connect("dbi:SQLite:$dbfile")
        or die "Couldn't connect to database: " . DBI->errstr;

    # Disable synchronous writes to improve performance.
    sql_do($dbh{$dbfile}, 'PRAGMA synchronous = OFF');

    return $dbh{$dbfile};
}

sub usage ($exitvalue) {
    print STDERR <<END;

Usage: @{[basename($0)]} [options] [files]

    -h          Print this message.
    -r          Work recursively.
    -v          Be more verbose.
    -D          Turn on debugging.
    -n          Don't link anything, just list what would be one (dry run).
    -t          Only link files that have identical timestamps.
    -c file     Cache results in file.

END

    exit $exitvalue;
}

sub info (@message) {
    say @message if ($verbose or $debug);
}

sub debug (@message) {
    say STDERR @message if ($debug);
}

sub recurse_into ($dbh, $dir) {
    if (opendir(DIR, $dir)) {
        for my $x (grep(!/^\.\.?$/, readdir(DIR))) {
            my @statbuf = lstat("$dir/$x");
            if (-d(_)) {
                recurse_into($dbh, "$dir/$x");
            } elsif (-f(_)) {
                stuff($dbh, "$dir/$x", @statbuf);
            } else {
                debug(basename($0),
                    ": '$dir/$x' is not a plain file, skipping...");
            }
        }
    } else {
        warn "Can't open $dir: $!\n";
    }
}

sub stuff ($dbh, $file, @statbuf) {
    numtotal(1);

    sql_execute($dbh,
        'insert into inode'
        . ' (dev,inum,nlink,uid,gid,size,blocks,mtime)'
        . ' values (?,?,?,?,?,?,?,?)'
        . ' on conflict do'
        . ' update set nlink=?,uid=?,gid=?,size=?,blocks=?,mtime=?',
        @statbuf[0..1],
        @statbuf[3..5],
        $statbuf[7],
        $statbuf[12],
        $statbuf[9],
        @statbuf[3..5],
        $statbuf[7],
        $statbuf[12],
        $statbuf[9]);

    sql_execute($dbh, 'insert into file (dev,inum,name) values (?,?,?)',
        @statbuf[0..1], $file);

    return 1;
}

sub checksum ($dbh, $context, $i) {
    my $file = $i->{'name'};

    my $fh = new FileHandle $file, "r";
    if (!defined($fh)) {
        warn "Failed to open $file: $!\n";
        return;
    }

    num(1);

    $context->reset();
    $context->addfile($fh);
    $fh->close();
    my $hash = $context->hexdigest();
    debug("$hash  $file");

    sql_execute($dbh, "update inode set md5=? where dev=? and inum=?",
        $hash, $i->{'dev'}, $i->{'inum'});
}

sub sql_do ($dbh, @sql) {
    for my $statement (@sql) {
        debug("Executing \"$statement\"...");
        my $result = $dbh->do($statement)
            or die "SQL statement failed:\n    $statement\n"
                . $dbh->errstr . "\n";
    }
}

sub sql_execute ($dbh,$sql,@values) {
    my $sth = $dbh->prepare($sql)
        or die "prepare($sql) failed: " . $dbh->errstr . "\n";

    $sth->execute(@values)
        or die $sql . " (" . join(",", @values) . ") failed: "
            . $dbh->errstr . "\n";
    debug($sql . " (" . join(",", @values) . ")");

    return $sth;
}

sub db_upgrade ($dbh, $version, $dbver) {
    my $newversion = $version+1;

    if ($version == 1) {
        # Add the dev_inum index and clear_md5 trigger.
        my @update = (
            begin_transaction(),
            create_index_dev_inum_v2(),
            create_trigger_clear_md5_v2(),
            "update linkdups set version=$newversion where version=$version",
            commit(),
        );
        sql_do($dbh, @update);
    } else {
        # FIXME: We should be able to upgrade the database.
        die "Need to upgrade database from version '$version' to version '$dbver'.";
    }

    db_upgrade($dbh, $newversion, $dbver) unless ($newversion == $dbver);
}

sub initdb ($dbh) {
    my @newdb = (
        begin_transaction(),
        create_table_linkdups_v1(),
        create_table_inode_v1(),
        create_index_dev_inum_v2(),
        create_trigger_clear_md5_v2(),
        commit(),
    );

    my $temporary = $debug ? "" : "temporary";
    my @file_table = (
            begin_transaction(),
            create_table_file_v1($temporary),
            commit(),
        );

    my $dbver = dbver();

    if ($dbh->selectrow_array("select * from sqlite_master where type='table'")) {
        my $result = $dbh->selectrow_arrayref("select version from linkdups");

        if (defined($result)) {
            my $version = $result->[0];

            if ($version == $dbver) {
                debug("Found a version $version database.");
            } elsif ($version > $dbver) {
                die "Found version '$version' database.  Expected version '$dbver'.";
            } elsif ($version > 0 and $version < $dbver) {
                db_upgrade($dbh, $version, $dbver);
            } else {
                die "Found unknown version '$version' database";
            }
        } else {
            # FIXME: Consider re-initializing the database?
            die 'Unable to determine schema version of existing database.';
        }
    } else {
        debug("Initializing database...");

        sql_do($dbh, @newdb);

        sql_execute($dbh, "insert into linkdups values (?)", $dbver);
    }

    if ($dbh->selectrow_array("select name from sqlite_master where type='table' and tbl_name='file'")) {
        debug("Dropping existing file table");
        sql_do($dbh, "drop table file");
    }

    debug("Initializing new file table");
    sql_do($dbh, @file_table);

    return 1;
}

sub query_string (@append) {
    state @query;

    push(@query, @append) if @append;

    return join(" || '.' || ", @query);
}

my %opt;
getopts('rvDnthc:', \%opt) or usage(1);

usage(0) if $opt{'h'};

my $recursive = defined($opt{'r'}) ? 1 : 0;
my $usetimes  = defined($opt{'t'}) ? 1 : 0;
$verbose      = defined($opt{'v'}) ? 1 : 0;
$debug        = defined($opt{'D'}) ? 1 : 0;
$dryrun       = defined($opt{'n'}) ? 1 : 0;

my $dbfile = defined($opt{'c'}) ? $opt{'c'} : ":memory:";

$SIG{'USR1'} = sub {
        say STDERR "files found: " . numtotal() . ", files checked: " . num() . ", bytes "
            . ($dryrun ? "recoverable" : "saved") . ": " . total();
    };

my $start = 0;

if ($verbose or $debug) {
    eval { use Time::HiRes qw(gettimeofday tv_interval); };
    $start = [gettimeofday] if (!$@);
}

my @files;
if (@ARGV) {
    @files = @ARGV;
} else {
    if ($recursive) {
        @files = (".");
    } else {
        usage(1);
    }
}

my $dbh = dbh($dbfile);

initdb($dbh);

# Pass 1 - stat() everything.
debug("\n### PASS 1 - stat ###\n");

my @statbuf = ();
my $pass1 = 0;

for my $file (@files) {
    if (!(@statbuf = lstat($file))) {
        warn basename($0), ": $file: $!\n";
        next;
    }

    if ($recursive and (-d(_))) {
        recurse_into($dbh, $file);
    } elsif (-f(_)) {
        stuff($dbh, $file, @statbuf);
    } else {
        warn "$file: not a regular file\n";
        next;
    }
}

if ($verbose or $debug) {
    my $elapsed;

    if ($start) {
        $pass1 = [gettimeofday];
        $elapsed = tv_interval($start, $pass1);
    } else {
        $pass1 = time;
        $elapsed = $pass1-$^T;
    }
    info(numtotal() . " files scanned in $elapsed seconds.");
}

my $context = new Digest::MD5;

# Pass 2 - Check for potential duplicates and md5sum them.
debug("\n### PASS 2 - Check for duplicates ###\n");

query_string('inode.dev', 'inode.size');
query_string('inode.mtime') if ($usetimes);

my $sth = sql_execute($dbh,
    "select distinct inode.dev,inode.inum"
    . " from inode,file where inode.dev=file.dev and inode.inum=file.inum"
    . " and inode.md5 is null"
    . " and (@{[query_string()]}) in"
    . " (select (@{[query_string()]}) as stuff"
    . " from inode,file where inode.dev=file.dev and inode.inum=file.inum"
    . " group by stuff having count(stuff)>1)"
    . " order by inode.blocks desc,inode.size desc");

while (my $inode = $sth->fetchrow_hashref()) {
    my $sth = sql_execute($dbh,
        "select inode.dev,inode.inum,inode.blocks,inode.size,file.name"
        . " from inode,file where inode.dev=file.dev and inode.inum=file.inum"
        . " and file.dev=? and file.inum=?"
        . " limit 1",
        $inode->{'dev'},
        $inode->{'inum'});
    my $file = $sth->fetchrow_hashref();
    debug("Found potential duplicate: " . $file->{'name'}
        . " [" . $file->{'dev'} . "/" . $file->{'inum'} . "] size="
        . $file->{'size'} . " (" . $file->{'blocks'} . " blocks)");
    checksum($dbh, $context, $file);
}

info(num() . " files checked in "
    . ($start ? tv_interval($pass1) : time-$pass1)
    . " seconds (" . numtotal() . " files scanned).");

# Pass 3 - Link duplicates.
debug("\n### PASS 3 - Link duplicates ###\n");

query_string('inode.md5');
$sth = sql_execute($dbh,
    "select distinct inode.dev,inode.size,inode.md5"
    . ($usetimes ? ",inode.mtime" : '')
    . " from inode,file where inode.dev=file.dev and inode.inum=file.inum"
    . " and (@{[query_string()]}) in"
    . " (select distinct (@{[query_string()]}) as stuff"
    . " from inode,file where inode.dev=file.dev and inode.inum=file.inum"
    . " group by stuff having count(stuff)>1)"
    . " order by inode.blocks desc,inode.size desc,inode.nlink desc");

while (my $dup = $sth->fetchrow_hashref()) {
    info("Processing duplicate "
        . $dup->{'md5'}
        . " (size "
        . $dup->{'size'}
        . " bytes)...");

    my @args = ($dup->{'dev'}, $dup->{'size'}, $dup->{'md5'});
    push(@args, $dup->{'mtime'}) if ($usetimes);
    my $filesth = sql_execute($dbh,
        "select file.name,file.dev,file.inum from inode,file"
        . " where inode.dev=file.dev and inode.inum=file.inum"
        . " and inode.dev=? and inode.size=? and inode.md5=?"
        . ($usetimes ? " and inode.mtime=?" : '')
        . " order by inode.blocks desc,inode.nlink desc",
        @args);
    my $file = $filesth->fetchall_arrayref();
    if ($debug) {
        use Data::Dumper;
        debug(Dumper($file));
    }

    next unless (@{$file} > 1);

    my @unique = uniq(map { join(':', @$_[1, $#_]) } @{$file});
    unless (@unique > 1) {
        debug(scalar(@{$file}) ." entries for the same file, skipping...");
        next;
    }

    debug("Linking " . scalar(@unique) . " duplicates ("
        . scalar(@{$file}) . " files) of size " . $dup->{'size'});

    for my $link_candidate (@$file[1, $#$file]) {
        my ($source, $source_dev, $source_inum) = @{$file->[0]};
        my ($destination, $destination_dev, $destination_inum) = @$link_candidate;

        if ($source_dev == $destination_dev and $source_inum == $destination_inum) {
            debug("Skipping existing hardlinks:\n  $source\n  $destination");
            next;
        }

        my @src_stat = stat($source);
        my @dst_stat = stat($destination);
        # TODO: Sanity-check the size/timestamp against the database.
        debug("$source_dev:$source_inum ("
            . $src_stat[3]
            . " links) -> $destination_dev:$destination_inum ("
            . $dst_stat[3]
            . " links)");

        unless ($dryrun) {
            debug "unlinking $destination...";
            unless (unlink($destination)) {
                warn "unlink($destination) failed: $!\n";
                next;
            }

            debug "linking $source to $destination...";
            link($source, $destination)
                or die "link($source, $destination) failed: $!\n";

            my $nlink = $src_stat[3]+1;
            my @after = stat($source);
            warn "Actual link count != expected!\n" if ($nlink != $after[3]);
        }

        total($dup->{'size'});
    }
}

info total() . " bytes "
    . ($dryrun ? 'would be ' : '')
    . "saved.";

$dbh->disconnect;

# vi: set ai et:
